{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5: Neural networks\n",
    "\n",
    "## [Scientific Computing with Python](http://scicompy.yoavram.com)\n",
    "## Yoav Ram\n",
    "\n",
    "# General instructions\n",
    "\n",
    "1. Do not remove any text or code cells; do not leave redundent print messages.\n",
    "1. When instructed to implement a function, use the given function names and parameters lists; failure to do so may cause test functions to fail during grading.\n",
    "1. When instructed to generate a plot, make sure that the plot is clear, that axes are propely labeled, and that the notebook is saved with the plot inline, so that the grader can see the plot without running the code. Make sure that you re-generate the plot if you changed the code!\n",
    "1. Code lines with a triple comment `###` should not be removed or modified, they are used for automatic grading.\n",
    "1. Note that there are 3 exercises and the last cell in the notebook says **end of assignment**; if you are missing anything please download the origianl file from the course website.\n",
    "1. Your code should run within a reasonable time (a few minutes) and you should use idioms learned in class, e.g. array opreations, numba, multiprocessig.\n",
    "1. Questions regarding the exercises should be posted to the course forum at the designated group (i.e. \"assignment5\"). You can post questions anonymously. You can also visit the Office Hours, but please do not email the course staff with questions about the exercise.\n",
    "1. Intructions for submitting the exercise are on the [course website](https://scicompy.yoavram.com/assignments).\n",
    "\n",
    "# Cloud computing with GPU\n",
    "\n",
    "**In Ex 2 and Ex 3 there is a benefit in running on a computer with a GPU. There are two ways to do that:**\n",
    "1. Use [**Google Colaboratory**](http://colab.research.google.com) (free.) Colaboratory provides free GPU usage for 12 hours inside a Jupyter notebook. Once you are inside colaboratory, upload this notebook, and change the runtime to Python 3 + GPU. Don't forget to download your notebook when you finish (from the File menu), although it will be saved in your Google Docs.\n",
    "\n",
    "~~1. Use **AWS Educate**. You will recieve an email with instructions on how to redeem your AWS Educate account, an which you will have \\$50 credits to use for AWS services. [Instructions are provided](https://aws.amazon.com/blogs/machine-learning/get-started-with-deep-learning-using-the-aws-deep-learning-ami/) for setting up a deep learning environment with conda, jupyter, and keras. Note that when you go over the credit limit (\\$50) your account will be suspended and you will not have access to your work, so plan accordingly. Some GPU-enabled instances estimated  costs are: p2.xlarge (Tesla K80) 22 USD/day; p3.2xlarge (2 x Tesla v100) 75 USD/day; p3.16xlarge (8 x Tesla v100) 600 USD/day. At this stage you should probably take the cheapest one.`~~\n",
    "\n",
    "It's can be worth the effort: epochs on the dataset used in Ex 2 and Ex 3 take about 15 secs on colaboratory, compared to 40 secs on my laptop. \n",
    "But it is not mandatory to work with a GPU, you can use your local CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numba\n",
    "import keras\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is required for Ex 1\n",
    "def display_image(im):\n",
    "    plt.imshow(im.reshape((28, 28)), cmap='gray_r')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "def fully_connected(ninputs, noutputs):\n",
    "    boundary = np.sqrt(6 / (ninputs + noutputs))\n",
    "    return np.random.uniform(-boundary, boundary, size=(ninputs, noutputs))\n",
    "\n",
    "def softmax(x):\n",
    "    expx = np.exp(x - x.max(axis=1, keepdims=True))\n",
    "    return expx / expx.sum(axis=1, keepdims=True)\n",
    "\n",
    "def accuracy(Yhat, Y):\n",
    "    return (Y.argmax(axis=1) == Yhat.argmax(axis=1)).mean()\n",
    "\n",
    "def cross_entropy(Yhat, Y):\n",
    "    ylogy = Y * np.log(Yhat)\n",
    "    return -ylogy.sum()\n",
    "\n",
    "def ReLU(X):\n",
    "    return np.maximum(X, 0)\n",
    "\n",
    "def dReLU(X):\n",
    "    return (X > 0).astype(float)\n",
    "\n",
    "def drop(X, keep_prob=1):\n",
    "    if keep_prob < 1:\n",
    "        X = X.copy() # we don't want to change X\n",
    "        keeps = np.random.rand(X.shape[1]) < keep_prob\n",
    "        # X.shape is (nsamples, nfeatures)\n",
    "        X[:, ~keeps] = 0 # ignore\n",
    "        X[:, keeps] *= (1/keep_prob) # normalize\n",
    "    return X\n",
    "\n",
    "def predict(Ws, X):\n",
    "    if X.ndim == 1:\n",
    "        X = X.reshape((1, -1))\n",
    "    return feed_forward(Ws, X, keep_prob=1)[-1]\n",
    "\n",
    "def display_prediction(idx):\n",
    "    prediction = predict(Ws, X_test[idx, :]).argmax()\n",
    "    print(prediction)\n",
    "    return display_image(X_test[idx])\n",
    "\n",
    "def loss(Ws, X, Y):\n",
    "    Yhat = predict(Ws, X)\n",
    "    return cross_entropy(Yhat, Y)\n",
    "\n",
    "def gradient_check(Ws, X, Y, Δ=1e-5):\n",
    "    dWs = back_propagation(Ws, X, Y, keep_prob=1)\n",
    "    Ws_ = [W.copy() for W in Ws]\n",
    "\n",
    "    for i, (W_, dW_) in enumerate(zip(Ws_, dWs)):\n",
    "        print('W{}'.format(i+1))\n",
    "        for i in range(W_.shape[0]):\n",
    "            for j in range(W_.shape[1]):\n",
    "                dw = dW_[i, j]\n",
    "                W_[i,j] += Δ\n",
    "                loss1 = loss(Ws_, X, Y)\n",
    "                W_[i,j] -= 2*Δ\n",
    "                loss2 = loss(Ws_, X, Y)\n",
    "                W_[i,j] += Δ\n",
    "                dw_ = (loss1 - loss2) / (2 * Δ)\n",
    "                rel_error = abs(dw - dw_) / abs(dw + dw_)\n",
    "                if not np.isclose(dw_, dw):\n",
    "                    print(i, j, dw, dw_, rel_error)\n",
    "                    \n",
    "def average(prev, curr, β):\n",
    "    return [\n",
    "        β * p + (1 - β) * c\n",
    "        for p, c\n",
    "        in zip(prev, curr)\n",
    "    ]\n",
    "    \n",
    "class AdamOptimizer:\n",
    "    def __init__(self, α=0.001, β1=0.9, β2=0.999, ϵ=1e-8):\n",
    "        self.α = α\n",
    "        self.β1 = β1\n",
    "        self.β2 = β2\n",
    "        self.ϵ = ϵ\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        self.t = 0\n",
    "\n",
    "    def send(self, gradients):\n",
    "        if self.m is None:\n",
    "            self.m = [0] * len(gradients)\n",
    "        if self.v is None:\n",
    "            self.v = [0] * len(gradients)\n",
    "\n",
    "        self.t += 1\n",
    "        αt = self.α * np.sqrt(1 - self.β2**self.t) / (1 - self.β1**self.t)\n",
    "        self.m = average(self.m, gradients, self.β1)        \n",
    "        self.v = average(self.v, (g*g for g in gradients), self.β2)\n",
    "\n",
    "        updates = [-αt * mi / (np.sqrt(vi) + self.ϵ) for mi, vi in zip(self.m, self.v)]\n",
    "        for upd in updates:\n",
    "            assert np.isfinite(upd).all()\n",
    "        return updates\n",
    "    \n",
    "def trainer(Ws, X, Y, optimizer, batch_size=50, keep_prob=1):    \n",
    "    nsamples = X.shape[0]\n",
    "    batch = 0\n",
    "    while True:\n",
    "        # get next batch\n",
    "        start = (batch * batch_size) % nsamples\n",
    "        stop = start + batch_size\n",
    "        batch_idx = range(start, stop)\n",
    "        X_, Y_ = X[batch_idx, :], Y[batch_idx, :]\n",
    "        \n",
    "        gradients = back_propagation(Ws, X_, Y_, keep_prob=keep_prob) # calculate gradients\n",
    "        \n",
    "        ΔWs = optimizer.send(gradients) # calculate updates\n",
    "        \n",
    "        for W, ΔW in zip(Ws, ΔWs): # apply updates\n",
    "            W += ΔW\n",
    "            \n",
    "        batch += 1\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex 1\n",
    "\n",
    "Let's load the data for MNIST digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()\n",
    "nsamples, width, height = X_train.shape\n",
    "nfeatures = width * height\n",
    "X_train = X_train.reshape(nsamples, nfeatures)\n",
    "X_test = X_test.reshape(-1, nfeatures)\n",
    "Y_train = keras.utils.to_categorical(Y_train)\n",
    "Y_test = keras.utils.to_categorical(Y_test)\n",
    "ncats = Y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement `feed_forward` and `back_propagation` from the FFN lecture using a `for` loop so that they work for any number of hidden layers.**\n",
    "\n",
    "Notes: \n",
    "- when implementing `back_propagation`, you can use the `gradient_check` function (from `A5.py`) to test that it works as expected.\n",
    "- please keep the functions signatures as supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(Ws, X, keep_prob=1): ###\n",
    "    # your code here\n",
    "    return layers ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(Ws, X, Y, keep_prob=1): ###\n",
    "    # your code here\n",
    "\n",
    "    # sanity checks ###\n",
    "    assert len(gradients) == len(Ws), (len(gradients), len(Ws)) ###\n",
    "    for dW, W in zip(gradients, Ws): ###\n",
    "        assert dW.shape == W.shape, (dW.shape, W.shape) ###\n",
    "    return gradients ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now **train the FFN model** with 2 or more hidden layers, and print its accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1008\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(predict(Ws, X_test), Y_test) ###\n",
    "print(\"Accuracy: {:.4f}\".format(acc)) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (12000): 0.9492\n"
     ]
    }
   ],
   "source": [
    "# train model here\n",
    "\n",
    "acc = accuracy(predict(Ws, X_test), Y_test) ###\n",
    "print(\"Accuracy ({:d}): {:.4f}\".format(batch, acc)) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex 2\n",
    "\n",
    "The Fashion-MNIST dataset contains 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images. This dataset can be used as a drop-in replacement for MNIST. The class labels are:\n",
    "\n",
    "\n",
    "| Label |\tDescription|\n",
    "|---|------------------|\n",
    "| 0 |\tT-shirt/top    |\n",
    "| 1 |\tTrouser        |\n",
    "| 2 |\tPullover       |\n",
    "| 3 |\tDress          |\n",
    "| 4 |\tCoat           |\n",
    "| 5 |\tSandal         |\n",
    "| 6 |\tShirt          |\n",
    "| 7 |\tSneaker        |\n",
    "| 8 |\tBag            |\n",
    "| 9 |\tAnkle boot     |\n",
    "\n",
    "See [keras docs](https://keras.io/datasets/).\n",
    "\n",
    "In this exercise we will train a CNN on the dataset. \n",
    "\n",
    "We'll get the data via [`keras.datasets`](https://keras.io/datasets/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras 2.2.4\n",
      "GPU: []\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "print('Keras', keras.__version__)\n",
    "from keras import backend as K\n",
    "print('GPU:', K.tensorflow_backend._get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data() ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert the images to a float32 between 0 and 1 and reshape to 28x28x1 (only one channel for black and white) because 2D convolutions expect 3D images (3rd dimension is channel or image).\n",
    "\n",
    "We also need to one-hot encode the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "x_test = x_test.reshape((-1, 28, 28, 1))\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 126,
       "width": 126
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(0, x_train.shape[0])\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(x_train[i, :, :, 0], cmap='gray_r')\n",
    "plt.xticks([]); plt.yticks([])\n",
    "print(y_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build, train, and score a CNN**.\n",
    "\n",
    "When I trained a CNN I got this accuracy of ~87% on the test set, see if you can top that.\n",
    "However, I was not successful using Adam optimizer, but rather changed to RMSprop optimizer with `lr=0.0001` and `decay=1e-6` as recommended somewhere online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Keras CNN model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 34s 566us/step - loss: 0.8884 - acc: 0.6866 - val_loss: 0.5663 - val_acc: 0.7917\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 43s 714us/step - loss: 0.5645 - acc: 0.7933 - val_loss: 0.4875 - val_acc: 0.8217\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 34s 566us/step - loss: 0.5012 - acc: 0.8174 - val_loss: 0.4446 - val_acc: 0.8383\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 34s 560us/step - loss: 0.4622 - acc: 0.8321 - val_loss: 0.4243 - val_acc: 0.8452\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 35s 577us/step - loss: 0.4352 - acc: 0.8428 - val_loss: 0.3969 - val_acc: 0.8579\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 37s 616us/step - loss: 0.4148 - acc: 0.8502 - val_loss: 0.3822 - val_acc: 0.8646\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 37s 624us/step - loss: 0.3986 - acc: 0.8569 - val_loss: 0.3701 - val_acc: 0.8665\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 36s 600us/step - loss: 0.3838 - acc: 0.8617 - val_loss: 0.3575 - val_acc: 0.8715\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 40s 666us/step - loss: 0.3721 - acc: 0.8673 - val_loss: 0.3501 - val_acc: 0.8736\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 39s 656us/step - loss: 0.3618 - acc: 0.8697 - val_loss: 0.3451 - val_acc: 0.8770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11e3a9080>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 157us/step\n",
      "Test loss: 0.34512671473026274\n",
      "Test accuracy: 0.877\n"
     ]
    }
   ],
   "source": [
    "# Score trained model\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=1) ###\n",
    "print('Test loss:', loss) ###\n",
    "print('Test accuracy:', acc) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use the model we trained on MNIST digits (in the lecture) to fit the MNIST-fashion dataset that we just worked on.\n",
    "This is a case of *transfer learning*, in which we transfer knowledge gained on one problem to solve another problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the model** we trained on MNIST digits dataset in the lecture using `keras.models.load_model`.\n",
    "Don't worry about the warning that Keras failed to load the optimizer state, as we don't care about the optimizer state.\n",
    "\n",
    "Note: this will fail if you haven't saved the model during the lecture.\n",
    "If you are using colaboratory or AWS, you will need to figure out how to upload the saved model from the lecture to the cloud.\n",
    "Maybe just copy the code from the lecture, then run and save. Or put the model .h5 file in dropbox, get a share link, and download it to colaboratory/AWS using a notebook cell with a `!wget url` command. Then change the h5 filepath below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_2 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               102500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 155,606\n",
      "Trainable params: 155,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoavram/miniconda3/envs/SciComPy/lib/python3.6/site-packages/keras/engine/saving.py:327: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "model = # load model here\n",
    "model.summary() ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We re-init the last layer (the output layer, the softmax layer), since we have the exact same shape for the output.\n",
    "However, similar approach can be used to replace the layer completely with a different layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = model.get_layer(index=-1) ###\n",
    "last_layer.kernel.initializer.run(session=K.get_session()) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile the model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retrain the model on the fashion data**, but only for 5 epochs.\n",
    "\n",
    "Note: the digits data used a different shape than the fashion data, and therefore the digits model started with a reshape layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 50s 832us/step - loss: 0.5492 - acc: 0.8081 - val_loss: 0.3453 - val_acc: 0.8738\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 52s 874us/step - loss: 0.3465 - acc: 0.8766 - val_loss: 0.3105 - val_acc: 0.8881\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 51s 852us/step - loss: 0.2977 - acc: 0.8944 - val_loss: 0.2930 - val_acc: 0.8961\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 52s 867us/step - loss: 0.2714 - acc: 0.9015 - val_loss: 0.2675 - val_acc: 0.9040\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 52s 863us/step - loss: 0.2475 - acc: 0.9096 - val_loss: 0.2774 - val_acc: 0.9007\n"
     ]
    }
   ],
   "source": [
    "# train model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 322us/step\n",
      "Test loss: 0.27736796258687973\n",
      "Test accuracy: 0.9007\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test.reshape(-1, 28, 28), y_test, verbose=1) ###\n",
    "print('Test loss:', scores[0]) ###\n",
    "print('Test accuracy:', scores[1]) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When starting from fresh (Ex 2), I got to validation accuracy 0.79 after one epoch and to 0.88 after 10 epochs.\n",
    "With this approach, I get to accuracy 0.87 after one epoch and 0.9 after 5 eopchs.\n",
    "So this approach is certainly faster, if you already have another network to start with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**end of assignment**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:SciComPy]",
   "language": "python",
   "name": "conda-env-SciComPy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
